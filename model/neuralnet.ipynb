{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2AbNDIdwMpU6iY14YMeRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasperSha/cloud_music/blob/main/neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ExrmUDxBlD"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkdVBrobxEhC"
      },
      "source": [
        "!gcloud config set project cluster-music"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6uqBlCxJUj"
      },
      "source": [
        "import os\n",
        "# create virtual directory for image data\n",
        "os.makedirs('song_images', exist_ok=True)\n",
        "\n",
        "# create virtual directory for frequency data\n",
        "os.makedirs('song_freqs', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZSW_YOIxOkD"
      },
      "source": [
        "# load metadata\n",
        "!gsutil cp gs://deepclustermusic/gcp_meta.csv .\n",
        "\n",
        "# load images\n",
        "!gsutil cp gs://deepclustermusic/song_images './song_images'\n",
        "\n",
        "# load frequency data\n",
        "!gsutil cp gs://deepclustermusic/song_freqs './song_freqs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpc1uAcpLmQQ"
      },
      "source": [
        "'''\n",
        "spectrogram image size=(224, 224)\n",
        "\n",
        "ideal params (leveraged with resnet18 model)\n",
        "  batch_size:\n",
        "    value: 64\n",
        "  sample_rate:\n",
        "    value: 44100\n",
        "  hop_length:\n",
        "    value: 308 \n",
        "  win_length:\n",
        "    value: 2205\n",
        "  n_mels:\n",
        "    value: 224\n",
        "  n_fft:\n",
        "    value: 4096\n",
        "  normalize:\n",
        "    value: True\n",
        "  mix_up:\n",
        "    value: 0.1\n",
        "  f_max:\n",
        "    value: 18000\n",
        "  arch:\n",
        "    value: resnet18\n",
        "  n_epochs:\n",
        "    values: [10, 20, 80] \n",
        "  trial_num:\n",
        "    values: [1, 2, 3, 4, 5]\n",
        "  fold:\n",
        "    values: [1, 2, 3, 4, 5]\n",
        "\n",
        "for audio classification with resnet18 pre-trained\n",
        "about 89.54% accuracy, in 80 epochs, little over 14 minutes, although I think this is with some heavy rental fees\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P8f0FOaw36v"
      },
      "source": [
        "# tensorflow syntax here\n",
        "def self_attention(in_shape, ch, k=8):\n",
        "  height, width, channel = in_shape\n",
        "  x = layers.Input(shape = [height, width, channel])\n",
        "\t\n",
        "  f = layers.Conv2D(ch // k, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  f = layers.MaxPooling2D()(f)\n",
        "  f = layers.Reshape((-1, f.shape[-1]))(f)\n",
        "\t\n",
        "  g = layers.Conv2D(ch // k, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  g = layers.Reshape((-1, g.shape[-1]))(g)\n",
        "\t\n",
        "  h = layers.Conv2D(ch // 2, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  h = layers.MaxPooling2D()(h)\n",
        "  h = layers.Reshape((-1, h.shape[-1]))(h)\n",
        "\t\n",
        "  s = tf.matmul(g, f, transpose_b=True)\n",
        "  s = keras.layers.Softmax()(s)\n",
        "\t\t\n",
        "  o = tf.matmul(s, h)\n",
        "\n",
        "  o = layers.Reshape((height, width, ch // 2))(o)\n",
        "  o = layers.Conv2D(channel, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(o)\n",
        "  o = Scalar()(o)\n",
        "  o = o + x\n",
        "\n",
        "  SA = keras.Model(inputs=x, outputs=o)\n",
        "\t\n",
        "  return SA\n",
        "\n",
        "\n",
        "class Scalar(layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(Scalar, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.gamma = tf.Variable(initial_value=tf.zeros(1), trainable=True)\n",
        "    self._trainable_weights=[self.gamma]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return layers.Rescaling(self.gamma)(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CevZCl2w-O0"
      },
      "source": [
        "def conv_model():\n",
        "  input = layers.Input(shape=(256, 128))\n",
        "\n",
        "  image = SpectralNorm(layers.Conv2D(128, (5, 5), strides=(1, 1), padding='same', input_shape=[256, 128, 1]))(input)\n",
        "  image = layers.LeakyReLU(image)\n",
        "  image = layers.Dropout(0.3)(image)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}