{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mel_collection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR8KcJs4GoGWu2i+xa76RD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasperSha/cloud_music/blob/main/feature_collection/mel_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyB1URlsGPD_"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sd1yZLvGVko"
      },
      "source": [
        "!gcloud projects list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "catXk9p_GWGX"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('song_images', exist_ok=True)\n",
        "\n",
        "os.makedirs('song_flacs', exist_ok=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40OZHaOuGb3n"
      },
      "source": [
        "# load audio every N batches\n",
        "# have to manually enter (only have to change tail input to starting index each time, head just adds to it)\n",
        "start = 0\n",
        "end = 500\n",
        "\n",
        "'''\n",
        "TODO: for each batch, create csv of just the id's of song images created, use that for reference(instead of loading the pngs)\n",
        "'''\n",
        "# load image records data\n",
        "!gsutil -m cp gs://deepclustermusic/song_images/*.csv .\n",
        "\n",
        "!gsutil ls gs://deepclustermusic/flac_files/spotify_yt_data/*.flac | tail -n +0 | head -n 500 | gsutil -m cp -n -I './song_flacs'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JYNW0U9GuhA"
      },
      "source": [
        "!pip install fastaudio &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjLjT5UNosBq"
      },
      "source": [
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.feature\n",
        "import librosa.display\n",
        "\n",
        "import skimage.io\n",
        "\n",
        "import torchaudio.transforms as ta\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5obQtS2KyGY"
      },
      "source": [
        "def norm_wav(sample):\n",
        "  return (sample - sample.mean()) / sample.std()\n",
        "\n",
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZvOKm2MrScV"
      },
      "source": [
        "mel_config = dict(\n",
        "    sr=44100,\n",
        "    hop_length=441,\n",
        "    win_length=1024, # 1024 combined with n_fft=4096 best; 2205 -> 50ms, 4410 -> 100ms\n",
        "    n_mels=256,\n",
        "    n_fft=4096,\n",
        ")\n",
        "\n",
        "# only first 10 seconds up to 2 minutes of each\n",
        "start_time = mel_config['sr'] * 10\n",
        "end_time = mel_config['sr'] * 120"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFoHM6PRovSz"
      },
      "source": [
        "flacs = list(glob.glob('/content/song_flacs/*.flac'))\n",
        "\n",
        "fin = list(glob.glob('*.csv'))\n",
        "finished_df = pd.concat((pd.read_csv(f) for f in fin))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM6rV0PYo70t"
      },
      "source": [
        "songs = []\n",
        "for fname in flacs:\n",
        "  song_id = fname.split('/')[-1].split('.')[0]\n",
        "  # if song_id in finished_df['song_id'].values:\n",
        "    print('already finished this one')\n",
        "    continue\n",
        "  songs.append(song_id)\n",
        "\n",
        "  signal, _ = torchaudio.load(fname)\n",
        "  if signal is None:\n",
        "    continue\n",
        "\n",
        "  # convert any stereo to mono\n",
        "  channel = signal.ndim\n",
        "  if channel == 2:\n",
        "    signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "\n",
        "  # get duration in seconds\n",
        "  num_elements = torch.numel(signal)\n",
        "  sr = mel_config['sr']\n",
        "  duration = int(num_elements/sr)\n",
        "\n",
        "  # set minimum duration\n",
        "  if duration < 100 or duration > 480:\n",
        "    continue\n",
        "\n",
        "  signal = signal.T\n",
        "  signal = signal[:,0]\n",
        "  signal = signal.numpy()\n",
        "\n",
        "  # normalize the signal\n",
        "  signal = norm_wav(signal)\n",
        "  window = signal[start_time:end_time]\n",
        "  mels = librosa.feature.melspectrogram(window, **mel_config)\n",
        "  img = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "  img = plt.imshow(img, aspect='auto')\n",
        "  plt.axis('off')\n",
        "  plt.savefig(\"./song_images/%s_melspec.png\"%song_id, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "  plt.clf()\n",
        "  plt.close('all')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGtvjUYPvL0N"
      },
      "source": [
        "df = pd.DataFrame(songs, columns=['song_id'])\n",
        "df.to_csv('%s_%s.csv'%(start, end), encoding='utf-8', index=False)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt1wYuDOL2CK"
      },
      "source": [
        "!gsutil -m cp -n song_images/*.png gs://deepclustermusic/song_images/\n",
        "!gsutil cp 0_500.csv gs://deepclustermusic/song_images/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}