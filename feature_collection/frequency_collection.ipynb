{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frequency_collection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNMig9VDJKLMqlvemjtPsBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasperSha/cloud_music/blob/main/frequency_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cq0dRNegEmo"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_joSYv8fgaFW"
      },
      "source": [
        "# !curl https://sdk.cloud.google.com | bash"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGO7ZKrhgnZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5232315-13c2-4f02-af80-68413213ea4e"
      },
      "source": [
        "!gcloud projects list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_ID             NAME                         PROJECT_NUMBER\n",
            "cloudmusic-330004      cloudmusic                   731970834007\n",
            "cluster-music          cluster-music                850659529381\n",
            "composed-field-268617  ReverseAddressLookUp         1042903851702\n",
            "solar-theory-326420    natural-language-processing  128859147416\n",
            "studenthelper-520f1    studenthelper                280871841346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2R0p3j5g8fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9e343a-dd97-43ff-e81e-27c06fdc4b64"
      },
      "source": [
        "!gcloud config set project cluster-music"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqnUUzUjJHS"
      },
      "source": [
        "import os\n",
        "# create virtual directory for frequency data\n",
        "os.makedirs('song_freqs', exist_ok=True)\n",
        "\n",
        "# create virtual directory for the flac files\n",
        "os.makedirs('song_flacs', exist_ok=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vAB5y1jh9Nu"
      },
      "source": [
        "# load audio every N batches\n",
        "# have to manually enter (only have to change tail input to starting index each time, head just adds to it)\n",
        "start = 1001\n",
        "end = 1500\n",
        "\n",
        "# load frequency data\n",
        "!gsutil -m cp gs://deepclustermusic/song_freqs/*.csv .\n",
        "\n",
        "!gsutil ls gs://deepclustermusic/flac_files/spotify_yt_data/*.flac | tail -n +1001 | head -n 500 | gsutil -m cp -n -I './song_flacs'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lv-dsg1YK9e"
      },
      "source": [
        "!pip install fastaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tAgHciqjFVw"
      },
      "source": [
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.stats import kurtosis, skew\n",
        "\n",
        "import librosa\n",
        "import librosa.feature\n",
        "\n",
        "import torchaudio\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXk0QmElWtjt"
      },
      "source": [
        "flacs = list(glob.glob('/content/song_flacs/*.flac'))\n",
        "\n",
        "# read finished frequency features in here\n",
        "finished = list(glob.glob('*.csv'))\n",
        "finished_df = pd.concat((pd.read_csv(f) for f in finished))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6Ou_bufIvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1e5247-a77b-4575-fa09-8e9bf6ad872e"
      },
      "source": [
        "songs = []\n",
        "for fname in flacs:\n",
        "  song_id = fname.split('/')[-1].split('.')[0]\n",
        "\n",
        "  if song_id in finished_df['id'].values:\n",
        "    print('already finished this one')\n",
        "    continue\n",
        "\n",
        "  signal, sr = torchaudio.load(fname)\n",
        "  channel = signal.ndim\n",
        "\n",
        "  # convert any stereo to mono\n",
        "  if channel == 2:\n",
        "    signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "\n",
        "  if signal is None:\n",
        "    continue\n",
        "\n",
        "  # get duration in seconds\n",
        "  num_elements = torch.numel(signal)\n",
        "  duration = int(num_elements/sr)\n",
        "\n",
        "  if duration < 120 or duration > 480:\n",
        "    continue\n",
        "\n",
        "  # transpose and squash dim, librosa expects dim=(n,) whereas torchaudio returns (1, n)\n",
        "  signal = signal.T\n",
        "  signal = signal[:,0]\n",
        "\n",
        "  s = {\n",
        "      'id': song_id,\n",
        "      'signal': signal.numpy(), # need to convert to np array, memory leak in storing tensor in df\n",
        "      'sr': sr,\n",
        "      'channel': channel,\n",
        "      'duration': duration\n",
        "  }\n",
        "  songs.append(s)\n",
        "\n",
        "df = pd.DataFrame(songs)\n",
        "\n",
        "signals_df = df.copy()\n",
        "\n",
        "features = [\n",
        "            'zero_crossing_rate', # percussive sounds\n",
        "            'spectral_centroid', # brightness\n",
        "            'spectral_rolloff', # majority of frequency within which song presides\n",
        "            'mfcc', # the perceptual shape(envelope of time power spectrum) of the sound\n",
        "            'spectral_contrast', # differences in peaks and valleys of amplitudes of the sound\n",
        "            'spectral_bandwidth', # total range of frequency bands\n",
        "            'spectral_flatness' # range between noisiness and 'tone'-ness of song (tone as in a pure note tone)\n",
        "            ]\n",
        "\n",
        "ZCR_BIAS = 1e-9\n",
        "\n",
        "for f in features:\n",
        "  audio_func = getattr(librosa.feature, f)\n",
        "\n",
        "  if f == 'zero_crossing_rate':\n",
        "    signals_df[f] = signals_df.apply(lambda x: audio_func(y=(x['signal'] + ZCR_BIAS)), axis=1)\n",
        "  elif f == 'spectral_flatness':\n",
        "    signals_df[f] = signals_df.apply(lambda x: audio_func(y=x['signal']), axis=1)\n",
        "  else:\n",
        "    signals_df[f] = signals_df.apply(lambda x: audio_func(y=x['signal'], sr=x['sr']), axis=1)\n",
        "    \n",
        "  signals_df['%s_mean'%f] = signals_df[f].apply(lambda x: np.mean(x))\n",
        "  signals_df['%s_var'%f] = signals_df[f].apply(lambda x: np.var(x, ddof=1))\n",
        "  signals_df['%s_kurtosis'%f] = signals_df[f].apply(lambda x: kurtosis(np.ndarray.flatten(x), fisher=True))\n",
        "  signals_df['%s_skew'%f] = signals_df[f].apply(lambda x: skew(np.ndarray.flatten(x)))\n",
        "\n",
        "  signals_df.drop(columns=[f], inplace=True, axis=1)\n",
        "\n",
        "# need to drop signal column or storage will blow up\n",
        "signals_df.drop(columns=['signal'], inplace=True, axis=1)\n",
        "print(signals_df.head())\n",
        "print(start, end)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            id     sr  ...  spectral_flatness_kurtosis  spectral_flatness_skew\n",
            "0  IrUkD07oUFg  48000  ...                  115.525460               10.832779\n",
            "1  JuwLQGWgYnA  48000  ...                  346.945147               18.467583\n",
            "2  F-zrm3vGbNw  48000  ...                  109.178706               10.516065\n",
            "3  J6M5O-9oAyY  44100  ...                    6.233759                2.869390\n",
            "4  HrBfLKR6HHM  48000  ...                 2742.430231               49.409058\n",
            "\n",
            "[5 rows x 32 columns]\n",
            "1001 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPbH37mLRYIH"
      },
      "source": [
        "signals_df.to_csv('%s_%s.csv'%(start, end), encoding='utf-8', index=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4Z6CPRTTvC_",
        "outputId": "5e58eb6f-89f6-4292-a315-b3eb20ac31d5"
      },
      "source": [
        "!gsutil cp -n 1001_1500.csv gs://deepclustermusic/song_freqs/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://1001_1500.csv [Content-Type=text/csv]...\n",
            "/ [1 files][255.3 KiB/255.3 KiB]                                                \n",
            "Operation completed over 1 objects/255.3 KiB.                                    \n"
          ]
        }
      ]
    }
  ]
}